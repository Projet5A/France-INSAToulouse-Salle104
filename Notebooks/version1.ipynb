{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we describe the code use to produce the baseline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#DATA_PATH = \"/kaggle/input/defi-ia-insa-toulouse\"\n",
    "DATA_PATH = '../Data'\n",
    "\n",
    "train_df = pd.read_json(DATA_PATH+\"/train.json\").set_index('Id')\n",
    "test_df = pd.read_json(DATA_PATH+\"/test.json\").set_index('Id')\n",
    "train_label = pd.read_csv(DATA_PATH+\"/train_label.csv\").set_index('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>She is also a Ronald D. Asmus Policy Entrepre...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is a member of the AICPA and WICPA. Brent ...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Aster has held teaching and research posi...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He runs a boutique design studio attending cl...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He focuses on cloud security, identity and ac...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          description gender\n",
       "Id                                                          \n",
       "0    She is also a Ronald D. Asmus Policy Entrepre...      F\n",
       "1    He is a member of the AICPA and WICPA. Brent ...      M\n",
       "2    Dr. Aster has held teaching and research posi...      M\n",
       "3    He runs a boutique design studio attending cl...      M\n",
       "4    He focuses on cloud security, identity and ac...      M"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = train_df\n",
    "Y = train_label\n",
    "\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luval\\anaconda3\\envs\\Defi\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\luval\\anaconda3\\envs\\Defi\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>gender</th>\n",
       "      <th>label</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198219</th>\n",
       "      <td>She is trained in cognitive behavior therapy ...</td>\n",
       "      <td>F</td>\n",
       "      <td>22</td>\n",
       "      <td>psychologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>He spent over 8 years in PWC’s Audit and Advi...</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>accountant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126976</th>\n",
       "      <td>For a number of years Haig has been exploring...</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184223</th>\n",
       "      <td>Prior to joining the firm, Michelle was the h...</td>\n",
       "      <td>F</td>\n",
       "      <td>26</td>\n",
       "      <td>attorney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144124</th>\n",
       "      <td>While his early works were greatly influenced...</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description gender  label  \\\n",
       "Id                                                                        \n",
       "198219   She is trained in cognitive behavior therapy ...      F     22   \n",
       "1460     He spent over 8 years in PWC’s Audit and Advi...      M      9   \n",
       "126976   For a number of years Haig has been exploring...      M     19   \n",
       "184223   Prior to joining the firm, Michelle was the h...      F     26   \n",
       "144124   While his early works were greatly influenced...      M     25   \n",
       "\n",
       "       category_name  \n",
       "Id                    \n",
       "198219  psychologist  \n",
       "1460      accountant  \n",
       "126976     professor  \n",
       "184223      attorney  \n",
       "144124      composer  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ajout de colonnes avec label dans X_train :\n",
    "X_train[\"label\"]=Y_train.iloc[:,0]\n",
    "category_df = pd.read_csv(DATA_PATH+\"/categories_string.csv\")\n",
    "X_train[\"category_name\"] = [category_df[category_df[\"1\"]==x].values[0][0] for x in X_train[\"label\"].values]\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_train</th>\n",
       "      <th>Y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.006952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019107</td>\n",
       "      <td>0.018301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004224</td>\n",
       "      <td>0.004834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042041</td>\n",
       "      <td>0.042357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003758</td>\n",
       "      <td>0.003545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.021173</td>\n",
       "      <td>0.021685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.056665</td>\n",
       "      <td>0.056377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.003729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.030174</td>\n",
       "      <td>0.031607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.014181</td>\n",
       "      <td>0.015124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003856</td>\n",
       "      <td>0.003706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.053535</td>\n",
       "      <td>0.053062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.008011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.018693</td>\n",
       "      <td>0.018692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.058392</td>\n",
       "      <td>0.056998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.019619</td>\n",
       "      <td>0.020327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.025029</td>\n",
       "      <td>0.025345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.006434</td>\n",
       "      <td>0.006630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.019136</td>\n",
       "      <td>0.018393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.322991</td>\n",
       "      <td>0.319843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.067600</td>\n",
       "      <td>0.066759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.003959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.047497</td>\n",
       "      <td>0.049217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.004351</td>\n",
       "      <td>0.004857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.027067</td>\n",
       "      <td>0.026197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.015366</td>\n",
       "      <td>0.016690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.086477</td>\n",
       "      <td>0.087339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.010802</td>\n",
       "      <td>0.009461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Y_train    Y_test\n",
       "0   0.006877  0.006952\n",
       "1   0.019107  0.018301\n",
       "2   0.004224  0.004834\n",
       "3   0.042041  0.042357\n",
       "4   0.003758  0.003545\n",
       "5   0.021173  0.021685\n",
       "6   0.056665  0.056377\n",
       "7   0.004006  0.003729\n",
       "8   0.030174  0.031607\n",
       "9   0.014181  0.015124\n",
       "10  0.003856  0.003706\n",
       "11  0.053535  0.053062\n",
       "12  0.007430  0.008011\n",
       "13  0.018693  0.018692\n",
       "14  0.058392  0.056998\n",
       "15  0.019619  0.020327\n",
       "16  0.025029  0.025345\n",
       "17  0.006434  0.006630\n",
       "18  0.019136  0.018393\n",
       "19  0.322991  0.319843\n",
       "20  0.067600  0.066759\n",
       "21  0.003516  0.003959\n",
       "22  0.047497  0.049217\n",
       "23  0.004351  0.004857\n",
       "24  0.027067  0.026197\n",
       "25  0.015366  0.016690\n",
       "26  0.086477  0.087339\n",
       "27  0.010802  0.009461"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = pd.DataFrame(np.transpose([Y_train.Category.value_counts().values/Y_train.shape[0]]), index = Y_train.Category.value_counts().index, columns=['Y_train'])\n",
    "d2 = pd.DataFrame(np.transpose([Y_test.Category.value_counts().values/Y_test.shape[0]]), index = Y_test.Category.value_counts().index, columns=['Y_test'])\n",
    "d = pd.concat([d1,d2],axis=1,sort=False)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "\n",
    "The only cleaning transformation applied here is that we `lower` the data so that all words are lower case. \n",
    "Hence `research`and `Research` will be considered as similar word.\n",
    "\n",
    "You might want to look at other cleaning step such that removing stopwords, stemming words, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata \n",
    "import re\n",
    "import nltk\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = unicodedata.normalize('NFD', txt).encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "    txt = re.sub('[^a-z_]', ' ', txt)\n",
    "    english_stopwords = nltk.corpus.stopwords.words('english')\n",
    "    additional_stopwords = [\"work\",\"interest\",\"year\",\"currently\",\"including\",\"received\",\"focus\"]\n",
    "    stopwords = [unicodedata.normalize('NFD', sw).encode('ascii', 'ignore').decode(\"utf-8\") for sw in english_stopwords+additional_stopwords]\n",
    "    tokens = [w for w in txt.split() if (w not in stopwords)]\n",
    "    stemmer=nltk.stem.SnowballStemmer('english')\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luval\\anaconda3\\envs\\Defi\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luval\\anaconda3\\envs\\Defi\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train[\"description_cleaned\"] = [\" \".join(clean_txt(x)) for x in X_train[\"description\"].values]\n",
    "X_test[\"description_cleaned\"] = [\" \".join(clean_txt(x)) for x in X_test[\"description\"].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "\n",
    "We use TfidfVectorizer to transform words from text to numerical vector data.  \n",
    "\n",
    "More vectorize are available on scikit-learn -> https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text\n",
    "\n",
    "You also may want to have a look at words embedding methods (Word2vec, Glove, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB features: 153106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<173757x153106 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5383957 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "transformer = TfidfVectorizer().fit(X_train[\"description_cleaned\"].values)\n",
    "print(\"NB features: %d\" %(len(transformer.vocabulary_)))\n",
    "X_train_vect = transformer.transform(X_train[\"description_cleaned\"].values)\n",
    "X_test_vect = transformer.transform(X_test[\"description_cleaned\"].values)\n",
    "X_train_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning\n",
    "\n",
    "We use a simple Logistic Regression model with scikit learn default arguments'value to train the baseline model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=500,n_jobs=-1)\n",
    "model.fit(X_train_vect, Y_train.Category.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_vect)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = model.predict(X_train_vect)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "score_f1 = f1_score(Y_test.Category.values,predictions,average='macro')\n",
    "print(\"Score f1:\",score_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Category\"] = predictions\n",
    "baseline_file = test_df[[\"Id\",\"Category\"]]\n",
    "baseline_file.to_csv(\"/kaggle/working/baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
