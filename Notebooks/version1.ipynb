{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we describe the code use to produce the baseline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#DATA_PATH = \"/kaggle/input/defi-ia-insa-toulouse\"\n",
    "DATA_PATH = '../Data'\n",
    "\n",
    "train_df = pd.read_json(DATA_PATH+\"/train.json\").set_index('Id')\n",
    "test_df = pd.read_json(DATA_PATH+\"/test.json\").set_index('Id')\n",
    "train_label = pd.read_csv(DATA_PATH+\"/train_label.csv\").set_index('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>She is also a Ronald D. Asmus Policy Entrepre...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is a member of the AICPA and WICPA. Brent ...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Aster has held teaching and research posi...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He runs a boutique design studio attending cl...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He focuses on cloud security, identity and ac...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          description gender\n",
       "Id                                                          \n",
       "0    She is also a Ronald D. Asmus Policy Entrepre...      F\n",
       "1    He is a member of the AICPA and WICPA. Brent ...      M\n",
       "2    Dr. Aster has held teaching and research posi...      M\n",
       "3    He runs a boutique design studio attending cl...      M\n",
       "4    He focuses on cloud security, identity and ac...      M"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = train_df\n",
    "Y = train_label\n",
    "\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_train</th>\n",
       "      <th>Y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.006952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019107</td>\n",
       "      <td>0.018301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004224</td>\n",
       "      <td>0.004834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042041</td>\n",
       "      <td>0.042357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003758</td>\n",
       "      <td>0.003545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.021173</td>\n",
       "      <td>0.021685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.056665</td>\n",
       "      <td>0.056377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.003729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.030174</td>\n",
       "      <td>0.031607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.014181</td>\n",
       "      <td>0.015124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003856</td>\n",
       "      <td>0.003706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.053535</td>\n",
       "      <td>0.053062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.008011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.018693</td>\n",
       "      <td>0.018692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.058392</td>\n",
       "      <td>0.056998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.019619</td>\n",
       "      <td>0.020327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.025029</td>\n",
       "      <td>0.025345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.006434</td>\n",
       "      <td>0.006630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.019136</td>\n",
       "      <td>0.018393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.322991</td>\n",
       "      <td>0.319843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.067600</td>\n",
       "      <td>0.066759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.003959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.047497</td>\n",
       "      <td>0.049217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.004351</td>\n",
       "      <td>0.004857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.027067</td>\n",
       "      <td>0.026197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.015366</td>\n",
       "      <td>0.016690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.086477</td>\n",
       "      <td>0.087339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.010802</td>\n",
       "      <td>0.009461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Y_train    Y_test\n",
       "0   0.006877  0.006952\n",
       "1   0.019107  0.018301\n",
       "2   0.004224  0.004834\n",
       "3   0.042041  0.042357\n",
       "4   0.003758  0.003545\n",
       "5   0.021173  0.021685\n",
       "6   0.056665  0.056377\n",
       "7   0.004006  0.003729\n",
       "8   0.030174  0.031607\n",
       "9   0.014181  0.015124\n",
       "10  0.003856  0.003706\n",
       "11  0.053535  0.053062\n",
       "12  0.007430  0.008011\n",
       "13  0.018693  0.018692\n",
       "14  0.058392  0.056998\n",
       "15  0.019619  0.020327\n",
       "16  0.025029  0.025345\n",
       "17  0.006434  0.006630\n",
       "18  0.019136  0.018393\n",
       "19  0.322991  0.319843\n",
       "20  0.067600  0.066759\n",
       "21  0.003516  0.003959\n",
       "22  0.047497  0.049217\n",
       "23  0.004351  0.004857\n",
       "24  0.027067  0.026197\n",
       "25  0.015366  0.016690\n",
       "26  0.086477  0.087339\n",
       "27  0.010802  0.009461"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = pd.DataFrame(np.transpose([Y_train.Category.value_counts().values/Y_train.shape[0]]), index = Y_train.Category.value_counts().index, columns=['Y_train'])\n",
    "d2 = pd.DataFrame(np.transpose([Y_test.Category.value_counts().values/Y_test.shape[0]]), index = Y_test.Category.value_counts().index, columns=['Y_test'])\n",
    "d = pd.concat([d1,d2],axis=1,sort=False)\n",
    "d"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "\n",
    "The only cleaning transformation applied here is that we `lower` the data so that all words are lower case. \n",
    "Hence `research`and `Research` will be considered as similar word.\n",
    "\n",
    "You might want to look at other cleaning step such that removing stopwords, stemming words, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata \n",
    "import re\n",
    "import nltk\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = unicodedata.normalize('NFD', txt).encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "    txt = re.sub('[^a-z_]', ' ', txt)\n",
    "    english_stopwords = nltk.corpus.stopwords.words('english')\n",
    "    additional_stopwords = [\"work\",\"interest\",\"year\",\"currently\",\"including\",\"received\",\"focus\"]\n",
    "    stopwords = [unicodedata.normalize('NFD', sw).encode('ascii', 'ignore').decode(\"utf-8\") for sw in english_stopwords+additional_stopwords]\n",
    "    tokens = [w for w in txt.split() if (w not in stopwords)]\n",
    "    stemmer=nltk.stem.SnowballStemmer('english')\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return tokens "
   ]
  },
  {
=======
>>>>>>> parent of c76a5aa... add cleaning
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score f1: 0.730753874438092\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "score_f1 = f1_score(y_test,pred,average='macro')\n",
    "print(\"Score f1:\",score_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "\n",
    "The only cleaning transformation applied here is that we `lower` the data so that all words are lower case. \n",
    "Hence `research`and `Research` will be considered as similar word.\n",
    "\n",
    "You might want to look at other cleaning step such that removing stopwords, stemming words, etc."
   ]
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"description_lower\"] = [x.lower() for x in train_df.description]\n",
    "test_df[\"description_lower\"] = [x.lower() for x in test_df.description]"
   ]
  },
  {
>>>>>>> parent of c76a5aa... add cleaning
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "\n",
    "We use TfidfVectorizer to transform words from text to numerical vector data.  \n",
    "\n",
    "More vectorize are available on scikit-learn -> https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text\n",
    "\n",
    "You also may want to have a look at words embedding methods (Word2vec, Glove, etc..)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 3,
>>>>>>> parent of c76a5aa... add cleaning
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB features: 230368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<217197x230368 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9851657 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "transformer = TfidfVectorizer().fit(train_df[\"description_lower\"].values)\n",
    "print(\"NB features: %d\" %(len(transformer.vocabulary_)))\n",
    "X_train = transformer.transform(train_df[\"description_lower\"].values)\n",
    "X_test = transformer.transform(test_df[\"description_lower\"].values)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning\n",
    "\n",
    "We use a simple Logistic Regression model with scikit learn default arguments'value to train the baseline model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "Y_train = train_label.Category.values\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 20, 24, ..., 25, 26, 15], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19,  3, 19, ..., 19, 19,  1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model.predict(X_train)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Category\"] = predictions\n",
    "baseline_file = test_df[[\"Id\",\"Category\"]]\n",
    "baseline_file.to_csv(\"/kaggle/working/baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
